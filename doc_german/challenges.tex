\section{Technische Herausforderungen}
Die effiziente Geolokalisierung von Akteuren in einem sozialen Graph soll mit Hilfe von Computerprogrammen erfolgen. Sofern für diese Aufgabe keine besondere spezialisierte Informationsquelle zur Verfügung steht, werden hierfür im Allgemeinen Informationen aus dem Internet verwendet. Abhängig vom Zutrauen zur Korrektheit der Informationsquelle und dem Extraktionsverfahren mit dem die Informationen ermittelt werden, ändert sich die Qualität des Ergebnisses. Für eine problemlose Weiterverwendung der Daten aus einem Geolokalisierungsprozess ist es unabdingbar, dass die Qualität der Ergebnisse einschätzbar ist.

\subsection{Güte einer Quelle}
Die Bewertung der Güte einer Informationsquelle ist zumindest teilweise eine subjektive Entscheidung, die sich im besten Fall auf möglichst viele Indizien stützt. Da unser Datenmodell außerdem für mehrere Implementierungen einer Geolokalisierung übergreifend gültig sein soll, ist es nicht sinnvoll die Güte einer Informationsquelle in einer zu granularen Einheit abzubilden. Gibt man die Güte einer Quelle zum Beispiel mit einer Fließkommazahl zwischen 0 (nicht vertrauenswürdig) bis 1 (voll vertrauenswürdig) an, können die Indikatoren von verschiedenen Quellen sehr nahe beieinander liegen (z.B. $0.8$ und $0.83$). Auf Grund der subjektiven Anteile in der Bewertung und unterschiedlicher Implementierungen der Informationsextraktion in unterschiedlichen Programmen sagt ein so geringer Unterschied nichts darüber aus, welche Quelle eine bessere Güte hat. Wir haben uns daher stattdessen dazu entschieden, die Güte einer Quelle in relativ groben Einheiten zu unterscheiden, wie zum Beispiel ``sehr vertrauenswürdig'', ``vertrauenswürdig'', ``nicht vertrauenswürdig''. Da eine solch grobe Einteilung ein Rechnen\label{calc_likert} mit den Güteindikatoren verhindert und die Abstände zwischen den Einheiten unbestimmt groß sein können, bieten sich hierfür Likert-Skalen an. Eine genaue Festlegung findet sich im Abschnitt \ref{datenmodell} ``Datenmodell'' auf Seite \pageref{datenmodell}.

\subsection{Präzision einer Datumsangabe}
Neben der Korrektheit einer Information aus einer Quelle spielt auch der Zeitpunkt eine Rolle, auf den sich eine Information aus einer Quelle bezieht. Akteure, deren aufenthaltsorte man mittels Geolokalisierung finden möchte, bewegen sich im Laufe der Zeit zwischen verschiedenen Orten. Die Information, dass sich ein Akteur in New York befindet, ist erst dann hinreichend aussagekräftig, wenn erkennbar ist, in welchem Zeitraum dies der Fall war. Im günstigsten Falle ist eine solche Information mit einem konkreten Datum (Zeitpunkt) oder mit eindeutigen Anfangs- und Enddaten (Zeitintervall) annotiert. Ist dem nicht so, kann die Aussagekraft dieser Information stark nachlassen. Ohne jegliche Angabe eines Zeitpunktes für einen Auffenthaltsort einer Person, lässt sich nur die Aussage treffen, dass eine Person zwischen ihrem Geburts- und Todesdatum zu einem beliebigen Zeitpunkt an einem Ort war. Ähnlich zu den Likert-Skalen für die Qualität der Informationsquelle ist es auch hier sinnvoll, eine etwas gröbere Abstufung für die Genauigkeit des Zeitpunktes anzugeben. In diesem Fall beginnend bei der genauesten Angabe, nämlich ein konkreter ``Zeitstempel'', über etwas ungenauere Angaben wie ``Jahr`` oder ``Jahrzehnt`` bis hin zur ungenauesten Angabe ``Jahrhundert``. Zeitangaben, die noch unpräziser sind, werden hier nicht weiter beachtet. An dieser Stelle ist wiederum ein Hinweis auf den Anwendungsfall sinnvoll, je nach Zweck der Implementierung kann es entegegen der ersten Intuition sinnvoll sein, beispielsweise Zeitintervallen Vorrang vor konkreten Zeitpunkten zu geben. Hier sollte der Algorithmus, der die Datenstruktur befüllt und die Genauigkeit bewertet, konfigurierbar sein.

\subsection{Belegbarkeit der Informationen}
In aller Regel ist es von großem Interesse, herausfinden zu können von wo eine Information, die für die Geolokalisierung genutzt wurde, stammt. Zum Beispiel wenn man die Arbeit eines Geolokalisierungsprogrammes auf Korrektheit prüfen möchte, indem man die Informationen manuell zurückverfolgt und bewertet. Das führt bei Informationen, die aus dem schnellebigen Internet stammen zu zwei wesentlichen Problemen. \textbf{1}. Die Informationen aus dem Internet können sich schnell ändern oder gänzlich nur für kurze Zeit verfügbar sein. Es ist daher möglich, dass zum Zeitpunkt der Geolokalisierung eine andere Information in einer Quelle existiert hat, als zu dem Zeitpunkt, an dem man eine manuelle Überprüfung der Quelle vornehmen möchte. Aus diesem Grund sollte es möglich sein, den Beleg für eine Information (zum Beispiel Kopie einer Webseite), direkt in den Ergebnissen anzugeben. \textbf{2}. Das Internet hält größtenteils unstrukturierte Informationen bereit, die zum Beispiel mit Hilfe von Natural Language Processing erst maschinentauglich auswertbar gemacht werden müssen. Eine einzelne Quelle (``Webseite'') kann zudem mehrere Informationen enthalten. Man benötigt eine Möglichkeit, den Ort einer Quelle genauer anzugeben, als nur eine URL anzugeben. Auf Grund der Unstruktiertheit des Internets ist die einzige übergreifend mögliche Methode hierfür die Angabe eines Bytes, an dem (oder ab dem) eine Information gefunden wurde.

Die Angabe einer Kopie der Quelle sowie der Zeiger auf eine Stelle in dieser Quelle (Byte-Offset) ist ein eindeutiger Verweis auf die Informationsherkunft. Je nach Quelle kann eine solche Angabe jedoch sehr speicherintensiv werden, da die Kopie der Quelle sehr groß sein kann. Eine Quelle muss nicht unbedingt eine Textdatei sein (HTML, XML, ...), sondern kann jede beliebige Datei aus dem Internet sein. Dazu gehören auch große Binärdateien wie Bilder oder Videos, sofern ein Prozess aus diesen Dateien wichtige Informationen extrahieren kann. Aus diesem Grund soll eine solche Angabe in unserem Datenmodell optional und nur bei Bedarf aktivierbar sein.

\subsection{Einfache Repräsentation der Daten}
Um die Daten möglichst einfach zu repräsentieren und sie zwischen Prozessen austauschbar zu machen, empfehlen wir für dieses Modell JSON als Datenformat. JSON ist neben XML ein weit verbreitetes Datenformat in der Internetlandschaft, lässt sich aber einfacher und resourcensparender als XML durch andere Prozesse wieder einlesen. Das JSON Format unterstützt keine Binärdaten. Für die optionale Angabe einer Quelle in der Ausgabe ist es daher notwendig, die Quelle zu kodieren. Dafür nutzen wir in unserem Datenmodell die ``base64'' Kodierung. Dadurch kann die Größe einer Quellenkopie um etwa $33\%$ ansteigen \cite{ng2005study}. Ein weiterer Grund dafür, warum diese Angabe im Datenmodell optional ist. Eine weitere Übersicht über die verwendeten Technologien findet sich im Abschnitt \ref{technologies} ``Technologien''. Die Referenzimplementierung bietet bereit JSON-Schnittstellen.
